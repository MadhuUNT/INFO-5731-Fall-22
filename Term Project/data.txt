To answer the three research questions, we adopt a two-pronged approach – the first based on literature review, and the second on the development of a theoretical model. In our first prong: To understand what is fake news and disinformation (RQ1), we discuss the phenomenon and review the literature to disambiguate the terms. We also conduct a literature review to discuss the relationship of LIS with the disinformation phenomenon (RQ2). Finally, as part of our findings, we discuss current efforts that are being used to fight fake news (RQ3), and how these are isolated and inadequate.
Grant and Booth (2009) provide a typology of reviews and provide 14 types of reviews ranging from critical review, literature review, systematic review, scoping review, etc. Based on their typology, what we carry out in this study is a “literature review,” which is an examination of recent and current literature. “The literature review method seeks to identify what has been accomplished previously, allowing for consolidation, for building on previous work, for summation, for avoiding duplication, and for identifying omissions or gaps” (Grant and Booth, 2009, p. 97). In their review of scholarship on the fake news and misinformation phenomenon published between 2008 and 2017, Ha et al. (2021) found that a wide variety of journals from various disciplines publishing on the topic shows that it has captured interest from the scholarly community in general. Our aim in our review is to synthesize current and representative studies to answer the different parts of our research question. We limited our review to 30 years from 1992 to 2021. Google Scholar was used as the primary means to find the articles. We also used the Scopus database to find the articles, filtering articles relevant to LIS. For our searches, we used the keywords, “disinformation,” “misinformation,” “fake news,” “information behavior models,” “disinformation behavior” and their combinations. We read the title and the abstract of the articles that were retrieved. For seminal articles discussing disinformation, all the articles citing that particular article were also consulted. From the close to 200 articles that were consulted and reviewed, about one in three were found to be relevant to this paper. In total, 65 relevant research articles and publications were selected to be cited in the paper.
In our second prong, we build upon Karlova and Fisher's (2013) work that we adopt as a theoretical lens in our study. We are also guided by prior work on critical thinking and serendipity. Based on these, as well as the literature reviewed as part of the first prong, we propose a disinformation behavior framework and a simplified causal model for understanding the fake news phenomenon and the ways to fight it. As there are not enough existing information behavior theories or models on disinformation and fake news, we do not contrast or aggregate other prior theories of this phenomenon. However, we do discuss related information behavior theories and models and focus on completing and adding to one particular theory, Karlova and Fisher (2013) that we use as our lens. In building our proposed framework, we started with Karlova and Fisher and incorporated terms from the literature on disinformation and fake news, the literature on information behavior and context (see Agarwal, 2018), and on critical thinking and serendipity. This helped us arrive at a framework that both explains the disinformation and fake news phenomenon (RQ1) as well as ways to fight it (RQ3), thus answering two of our research questions. The framework is then simplified and presented as a causal research model (following Agarwal, 2018 – Designing Research Studies Incorporating Context, pp. 109–113).
In the sections that follow, we discuss the literature related to the phenomenon and terminology (RQ1), review the literature related to LIS (RQ2), and arrive at the findings of our study – which discuss current efforts to fight fake news (RQ3) and propose a theoretical framework (RQ1 and RQ3). We then discuss the findings and conclude the study.

We first use two matching strategies to alleviate potential selection bias and heterogeneity concerns to examine how the two platform interventions affect fake news dissemination.

Matching Strategies
Content-Based Matching: Latent Semantic Analysis
The first matching strategy is based on the idea of textual similarity, in which we match fake news and truthful news so that they are semantically similar. The basic logic is to quantify the news content in a numerical representation using natural language processing techniques and then apply similarity measures (e.g., cosine similarity and Euclidean distance) to infer semantic similarity between news posts. This approach has been implemented in various applications, such as collaborative filtering [29], incident risk factor identification [60], business proximity analysis [61], copycat detection [70], and customer agility measurement [74].

We start with truthful news posts. Due to the highly noisy dataset, a preliminary step is implemented to manually remove all posts that are (1) meaningless (with only emojis, numbers, or fewer than five words), (2) advertisements, and (3) forwarded posts. We remove all meaningless posts because they are not suitable for our content-based matching strategy. We ignore advertisements to avoid comparison with fake news posts, which are expected to be different from truthful news posts. Finally, we exclude forwarded posts because they are used to construct the post dissemination network. As a result, we obtain 23,535 truthful news posts, which are matched to our 1,514 fake news posts for further processing. We then tokenize all posts into a bag-of-words dictionary and remove all stop words and punctuation. Thus, each post is represented by a word vector, and each vector value indicates the frequency of a word occurring in the corresponding post. The term frequency-inverse document frequency (TF-IDF) technique is applied to all posts to normalize their corresponding word vectors. The result is a word-by-post matrix, with each row representing a post, each column representing a unique word, and each cell representing the TF-IDF value of the word in the post.

Next, we apply latent semantic analysis (LSA)15 to the word-by-post matrix to reduce the dimensionality and independency between words [39]. A dimensionality of 300 is chosen for LSA so that each word vector of a post is decomposed into a 300-dimensional feature vector. Finally, we match each fake news post to one or two truthful news posts based on the smallest angle calculated from the cosine similarity between their feature vectors. As a result, we obtain a matched sample of 1,586 truthful news posts and 1,514 fake news posts. The performance of the content-based matching method is reported in Appendix B1. Table 3 reports the summary statistics for truthful news posts after content-based matching.

Though the burgeoning Internet technology engenders a pervasive usage of multimedia for transferring data, the transfer usually happens over a slew of insecure network channels, making the Internet users vulnerable to malicious threats, eavesdropping, and other subversive activities. One of the prominent solutions is cryptography, such as the symmetric or asymmetric key cryptography, where the information sender encrypts the confidential data into a ciphered domain using an encryption key. Meanwhile, the receiver decrypts the sensitive data using a peculiar decryption key. This approach could successfully convert the original data into an unreadable ciphered text, thus mitigating information leakage. Nevertheless, the encrypted text is still conspicuously discernible in a scrambled form to human eyes, leading to potential suspicion and further scrutiny. Though sharing similar objectives with the cryptographic approach, steganography conceals the messages into a plausible medium such as authentic images or meaningful texts, making the hidden information barely perceptible to human eyes. In other words, the intended secret message is unlikely to draw attention to itself as an object of scrutiny. Furthermore, even if a malicious attacker successfully eavesdrops on the network packets in a Man-in-the-Middle attack (MITM), he cannot discern the original data from the covered one, which remarkably promotes the data confidentiality and integrity.

The Least Significant Bits (LSB) substitution method is conventionally employed to perform image steganography. The secret information is first converted to binary bits and then substituted in the LSBs of the cover image.

Recently, the blossom of deep learning has inspired a slew of researchers to leverage the generative adversarial networks (GANs) in steganography [6], [7]. Generally, the GANs consists of two models: a generator and a discriminator, which were trained in an adversarial manner to generate data samples that possess a close approximation of the real data distributions. Given that GANs methodology achieves stupendous performance in generation tasks, it is pervasively applicable in multifarious fields, including steganography.

Volkhonskiy first proposed an image steganography algorithm, SGAN [8]. Sparked by WGAN, Shi presented a similar method, SSGAN [9]. Though both approaches generally achieved a preferable performance, the images generated by SGAN and SSGAN are significantly warping in semantics, thus easily detectable by malicious attackers. Further, Tang proposed another steganography strategy ASDL-GAN [10]. The generator in this architecture learns from the input cover image and generates the steganographic images using a novel activation function - Ternary Embedding Simulator (TES). Meanwhile, the discriminator employs a XuNet to differentiate between real and fake samples. Though progressively enhanced, the model still has low capacity, and its security has not even transcended the conventional steganography algorithms such as S-UNIWARD [4]. Baluja proposed another convolutional neural network with a peculiar encoder-decoder architecture to discover the location where it is felicitous to embed secret information in the image [11]. Though the model possesses a large capacity, the hidden confidential information remains palpable after concealing it in the cover image, making it unresistant to steganalysis. Another similar method was proposed by Atique, which also incorporates encoder-decoder networks and CNN [12]. Their experiments manifest that the quality of the generated image is phenomenal, but the colour of the steganography image is conspicuously different from that of the cover image, making it effortlessly detectable by human eyes or staganalysis tools. Moreover, Zhu introduced CycleGAN for unpaired image-to-image translation using a cycle-consistent adversarial network [7]. The theory under the hood is that an image translated from one to another, after being translated back, should be identical to the original phrase. Other than image translation, CycleGAN has prevailing applications, including image steganography. Besides, Duan presented an innovative coverless steganography technique where the cover image is entirely unnecessary. Rather, it is generated based on secret information.

Inspired by Duan’s work, we proposed a coverless solution to perform steganography, where the secret information is embedded in the medium of a certain data domain, in lieu of a premeditated cover. Our proposed approach remarkably simplifies the steganographic process where the embedding cover is not mandatory. Furthermore, based on CycleGAN [7], we adopted the Generative Adversarial Network (GANs) with cycle-consistency to map original private data to fake data and reconstruct original information from the fake message. The experiments manifest that our reconstruction algorithm achieves remarkable performance in data capacity and secrecy. Moreover, our framework is applicable to various data domains, including images and texts. The generated steganographic information can be either from the same domain or an entirely different domain of the original data. Last but not least, unlike the conventional approaches, which only perform one layer of mapping, FakeSafe can perform multi-step steganographic mappings, which strikingly ensures the resistance to steganalysis and promotes the data security. Even if the malicious attackers eavesdrop on the steganographic message, it is almost infeasible for him to conjecture the original data due to the cascade of stenographic functions. To the best of our knowledge, this is the first time to propose a coverless solution to perform multi-step information steganography using a cycle-consistent adversarial network. Further, our framework is applicable to various domain domains.

Figure 2 shows the process flow for construction of seed and MIWS dataset. It contains four phases: data collection, seed data validation, data labelling and merging of data from different extremist ideology. Data collection is performed in two parts: first, seed data collection (explained in Section 3.1) and then collection of tweets or MIWS data collection (explained in Section 6.1). Seed data validation (explained in Section 5) is performed individually for each ideology. Similarly, data labelling (explained in Section 6) is done on each ideology separately. The reason behind this segregation is that the corpuses of both ideologies are different and the LDA topics (explained in Section 5) are based on the probability of keywords within the document of a particular corpus. In the last phase, merging of the ISIS/Jihadist and White supremacist labelled datasets is carried out (explained in Section 6).

The development methodology used a staged approach as described in the sections below. The project governance, in addition to the project team, included an advisory committee which consisted of representatives from key nursing and midwifery organisations: the Australian College of Midwives (ACM), the Australian College of Nursing (ACN), the Australian Nursing and Midwifery Federation (ANMF), Australian Nursing and Midwifery Accreditation Council (ANMAC), Australian Primary Health Care Nurses Association (APNA), Congress of Aboriginal and Torres Strait Islander Nurses and Midwives (CATSINaM), Digital Health Cooperative Research Centre (DHCRC), Australasian Institute of Digital Health Nursing and Midwifery Special Interest Group (AIDH-NaM), Nursing and Midwifery Board of Australia (NMBA), the Queensland Chief Nursing and Midwifery Officer (CNMO) as a conduit for information sharing with the Australian and New Zealand Chief Nursing and Midwifery Officers, the Agency’s  representatives including the Chief Clinical Information Officer (a nurse), an international expert, and a consumer representative. The advisory committee reviewed outputs at each stage of the project.

Deep Learning (DL) methods such as Recurrent Neural Networks (RNN) and their variations along with Convolutional Neural Networks (CNN) have demonstrated outstanding performance in false news identification tasks [16][17][18]. Saleh et al. [19] proposed an optimized CNN model that outperformed the baseline models when they compared their model to RNN and ML classifiers. The ensemble approach with DL models is widely used in this domain

Wu and Liu [12] proposed a system called trace miner for classifying social media posts. To detect the pathways of a message, they used the LSTM-RNN algorithm. Their proposed system achieved about 93.8% of the f1-score. However, using other measures such as ACC and the area under the curve (AUC) to view their point could be better. Zhang et al. [13] introduced a fake-detector inference model for automated fake news detection; they extract a distinct set of latent features from the text. This system builds a deep diffusive network for learning the impersonation of news articles and creators of these articles and subjects. They experimented on a real-world fake news dataset to compare the system they built with various models. The ACC score obtained by their system is about 63.0%. But they could use other datasets to evaluate the proposed method then compare the results of the two datasets.Gilda [14] created an application for detecting fake news using an open-source dataset. They use TF-IDF for extracting features and probabilistic context-free grammar detection on a corpus of about 11,000 articles. Their experiments were performed on several classification algorithms: SVM, SGD, gradient boosting (GD), bounded decision trees (BDT), and RF. They found that when using the TF-IDF method with the SGD algorithm, the ACC achieved was 77.2%. However, many feature extraction algorithms such as Word2Vec may enhance the results.Ko et al. [15] proposed a cognitive system using backtracking to detect fake news. Their results were an 85.0% detection rate. However, they did not clear how to detect fake news and subjective posts. Atodiresei et al. [16] proposed a system for identifying fake users and news on Twitter. Their system will receive a link to a tweet from a user and then compute the tweet credibility, also some statistics such as emotions. However, they didn’t clear what are the measure metrics they used to evaluate their work.
Pan et al. [17] proposed a B-TransE model system for detecting fake news according to news content using knowledge graphs. The experimental results of their works show that some of their approaches achieve above 80.0% of f1-score. The results could enhance if they combined two approaches together, such as content-based approaches with style-based approaches. Potthast et al. [18] proposed a new method for assessing style similarity across text categories using meta-learning. They show that fake news can be differentiated by its style. The experimental results show that their system achieved about 74.0% of ACC. Feature extraction algorithms like TF-IDF could enhance the results.

This paper will use a content analysis method to explore Orwell's relationship to information literacy. Two of Orwell's political diaries from the period 1940–42 were coded for key themes related to the ways in which Orwell discusses and evaluates information and news. These themes were then compared to UNESCO Five Laws of Media and Information Literacy. Textual analysis software NVivo 12 was used to perform keyword searches and word frequency queries in the digitised diaries.

So far, attempts for detecting fake news are limited to some conventional machine learning methods. The performance of neural networks for fake news detection can be improved by using different settings and components. one of the main settings in the training of a model is the loss function that, in recent years, has been used to improve the performance in many classification tasks.In this paper, we propose a new model based on CNNs for detecting fake news. In our proposed model, the CNN architecture for detecting fake news is enhanced by using margin loss. We also compare different varieties of word embeddings. We show proposed models achieve better results in comparison to the state-of-the-art methods.

The current state of the research in the field of fake news identification is summarised in the second section. The datasets of news Covid-19 used in the research are described in the second section. This section also describes the process of n-grams extraction from POS tags. Simultaneously, three POS tags-based techniques are proposed for preparing input vectors for decision trees classifiers. Subsequently, the same section discusses the process of decision trees modelling, the importance of finding the most suitable n-gram length and maximum depth. Finally, statistical evaluation of the performance of the modified techniques based on POS tags for fake news classification is explained in the same section. The most important results, together with an evaluation of model performance and time efficiency of the proposed techniques, are summarised in the fourth section.




